{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA가 어떻게 고차원 데이터를 저차원 데이터로 축소시켜 주는지를 살펴봤습니다.  \n",
    "차원을 축소시키면 차원의 저주 문제를 해결할 수 있고, 고차원의 데이터를 시각화하여 데이터의 특징을  \n",
    "한 눈에 파악할 수 있습니다.  \n",
    "이것은 차원 선택, 차원 추출의 여러 방법들이 가지는 공통적인 특징인데요.\n",
    "\n",
    "그 중에서도 PCA만이 가지는 가장 대표적인 특성은 데이터가 가진 중요한 정보를 최대한 보존하면서  \n",
    "차원을 축소한다는 점입니다. 챕터1에서 살펴본 6차원 데이터 user로 다시 예를 들어볼게요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "user = pd.read_csv('custom_data.csv')\n",
    "user.head(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](image/07-이미지1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 데이터를 5차원으로 줄이기 위해선 챕터 1에서 했던 것처럼 의미가 비슷한 `family_size`와 `children` 중  \n",
    "하나의 변수를 탈락시키면 됐습니다. 그렇게 하면 특정 변수가 가진 고유한 정보가 데이터에서 삭제되긴 하지만,  \n",
    "그래도 공통된 의미를 설명하는 부분이 큰 변수 중 하나를 삭제했으니 정보 손실이 엄청 크다고 할 순 없는데요.  \n",
    "하지만, 6차원 데이터를 차원 선택으로 2차원으로 줄이려면 어떻게 해야 할까요?  \n",
    "변수 간의 의미를 아무리 잘 고려하여 삭제할 변수를 선택하더라도 정보의 손실이 커지는 것을 막긴 어렵겠죠?  \n",
    "만약에 `family_size`와 `spent_all`이라는 두 변수만 선택했다면 다른 변수들에 있던 여러 정보가  \n",
    "이후 분석에 반영되지 못하게 되는 것입니다.\n",
    "\n",
    "PCA로 6차원을 2차원으로 축소시킬 경우, 새롭게 찾아진 두 개의 변수 PC1과 PC2는 6개 변수가 가진 정보를  \n",
    "종합적으로 고려하여 찾아진 변수이기 때문에 여러 변수들의 정보 손실을 최소화할 수 있습니다.  \n",
    "아래 예시만 봐도, 2개의 주성분으로 차원을 줄였을 때 기존 6개의 변수가 가진 정보 중 약 65%가량이 보존된다는 것을  \n",
    "알 수 있죠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 데이터 스케일링\n",
    "user_mean = user.mean()\n",
    "user_std = user.std()\n",
    "scaled_df = (user-user_mean)/user_std\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components = 6)\n",
    "pca.fit(scaled_df)\n",
    "scaled_df_pc = pca.transform(scaled_df)\n",
    "pca_df = pd.DataFrame(scaled_df_pc)\n",
    "pca_df.columns = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6']\n",
    "\n",
    "# 주성분의 설명력 확인\n",
    "num_components = len(pca.explained_variance_ratio_)\n",
    "\n",
    "x = np.arange(num_components)\n",
    "var = pca.explained_variance_ratio_\n",
    "\n",
    "plt.bar(x, var)  # bar plot 그리기\n",
    "\n",
    "plt.xlabel('PC')\n",
    "plt.ylabel('Variance_Ratio')\n",
    "plt.title('Scree plot')\n",
    "\n",
    "plt.savefig('img5.png', dpi=300)  # .savefig() : 그래프/플롯을 파일로 저장\n",
    "plat.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](image/07-이미지2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 변수가 가진 정보를 최대한 보존하는 방식으로 차원을 줄인다는 것이 PCA의 가장 큰 장점입니다.  \n",
    "데이터가 가진 변수의 정보를 잘 보존해 주기 때문에 PCA를 통해 차원을 축소시킨 데이터를 활용하여 예측 모델을  \n",
    "학습시키면 더 정확하고 일반화된 결과물을 얻을 수 있습니다.\n",
    "\n",
    "하지만, 단점도 있습니다. 먼저, PCA의 결과물로 찾아진 주성분의 의미를 해석하는 것이 어렵습니다.  \n",
    "주성분은 변수들 안에 포함된 여러 정보를 종합적으로 고려하여 새롭게 추출된 차원인데요.  \n",
    "하나의 주성분이 하나의 변수와 매칭되는 것이 아니라 여러 변수의 영향력을 종합적으로 받고 있기 때문에  \n",
    "결과로 확인된 주성분이 무엇을 의미하는지 명확하게 정의하기가 어렵습니다.\n",
    "\n",
    "또한, PCA는 거의 모든 데이터의 정보를 최대한 유지하는 방향으로 주성분을 추출해 주는데요.  \n",
    "해당 과정에 많은 연산이 필요합니다. 즉, 차원이 더 높은 데이터를 축소시킬수록 계산 비용이 급격히 증가되며  \n",
    "연산 시간이 오래 걸린다는 문제가 있죠. 따라서, PCA를 사용하기 전에는 데이터의 차원과 크기, 연산 환경을 고려하는 것이  \n",
    "필요하다는 단점이 있습니다."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
